{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if using colab\n",
    "# !git clone https://github.com/olijacklu/MLSuperb-Project.git\n",
    "\n",
    "# !cp -r /content/MLSuperb-Project/requirements.txt /content/\n",
    "# !cp -r /content/MLSuperb-Project/config/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/data/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/evaluation/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/models/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/training/ /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "\n",
    "from config.config import TRAIN_PAIRS, TORCH_DEFAULT_TYPE\n",
    "from data.preprocess import preprocess_data\n",
    "from data.dataset import ASRDataset\n",
    "from data.utils import data_loaders_and_vocab\n",
    "from models.utils import load_model, clean_memory\n",
    "from training.monolingual import train_and_evaluate_monolingual\n",
    "from training.multilingual import train_and_evaluate_multilingual\n",
    "from evaluation.test import test_model\n",
    "from evaluation.analysis import analyze_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/MVA/NLP/AlgorithmsSpeechNLP' # Important: Specify the path to the directory where the data is stored and where you wish to save any results\n",
    "\n",
    "torch.set_default_dtype(TORCH_DEFAULT_TYPE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = preprocess_data()\n",
    "\n",
    "with open(f'{base_dir}/ml_superb_dataset.json', 'w') as f:\n",
    "    json.dump(datasets, f, indent=2)\n",
    "\n",
    "print(f\"Found {len(datasets)} language-source pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_dir}/ml_superb_dataset.json', 'r') as f:\n",
    "    datasets = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(datasets)} language-source pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloaders for french monolingual data\n",
    "pair = TRAIN_PAIRS['fra1']\n",
    "_, _, _, char_mappings = data_loaders_and_vocab(datasets, pair, batch_size=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuned monolingual models dirs\n",
    "dir_ft_model_base = os.path.join(base_dir, 'reproduced_models/hubert_base/monolingual/')\n",
    "dir_ft_model_base_lora = os.path.join(base_dir, 'lora_models/hubert_base/monolingual/')\n",
    "dir_ft_model_q_lora = os.path.join(base_dir, 'qlora_models/hubert_base/monolingual/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments using the model fine-tuned with the paper approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(dir_ft_model_base, 'model.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ml-superb\", name=f\"monolingual_base_fr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "            model=model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            datasets=datasets,\n",
    "            char_mappings=char_mappings,\n",
    "            model_type=\"monolingual\",\n",
    "            data_pair=data_pair,\n",
    "            device=device,\n",
    "            num_samples=50,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments with the lora-ft model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(dir_ft_model_base_lora, 'model.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ml-superb\", name=f\"monolingual_lora_fr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "            model=model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            datasets=datasets,\n",
    "            char_mappings=char_mappings,\n",
    "            model_type=\"monolingual\",\n",
    "            data_pair=data_pair,\n",
    "            device=device,\n",
    "            num_samples=50,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments with q-lora-ft model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(dir_ft_model_q_lora, 'model.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ml-superb\", name=f\"monolingual_lora_fr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "            model=model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            datasets=datasets,\n",
    "            char_mappings=char_mappings,\n",
    "            model_type=\"monolingual\",\n",
    "            data_pair=data_pair,\n",
    "            device=device,\n",
    "            num_samples=50,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "clean_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
