{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-SUPERB Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if using colab\n",
    "# !git clone https://github.com/olijacklu/MLSuperb-Project.git\n",
    "\n",
    "# !cp -r /content/MLSuperb-Project/requirements.txt /content/\n",
    "# !cp -r /content/MLSuperb-Project/config/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/data/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/evaluation/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/models/ /content/\n",
    "# !cp -r /content/MLSuperb-Project/training/ /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "from config.config import TRAIN_PAIRS, TORCH_DEFAULT_TYPE\n",
    "from data.preprocess import preprocess_data\n",
    "from models.utils import load_model, clean_memory\n",
    "from training.monolingual import train_and_evaluate_monolingual\n",
    "from training.multilingual import train_and_evaluate_multilingual\n",
    "from evaluation.test import test_model\n",
    "from evaluation.analysis import analyze_layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set base directory (e.g. current working directory, has to be the same as where the data folder is stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/MVA/NLP/AlgorithmsSpeechNLP' # Important: Specify the path to the directory where the data is stored and where you wish to save any results\n",
    "\n",
    "torch.set_default_dtype(TORCH_DEFAULT_TYPE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data (creates JSON for easy lookup of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = preprocess_data()\n",
    "\n",
    "with open(f'{base_dir}/ml_superb_dataset.json', 'w') as f:\n",
    "    json.dump(datasets, f, indent=2)\n",
    "\n",
    "print(f\"Found {len(datasets)} language-source pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open JSON lookup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_dir}/ml_superb_dataset.json', 'r') as f:\n",
    "    datasets = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(datasets)} language-source pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify whether you want to apply LoRA and/or quantize the upstream model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora = False\n",
    "quantize = False\n",
    "\n",
    "lora_config = {\n",
    "    'r': 16,\n",
    "    'lora_alpha': 32,\n",
    "    'target_modules': [\"k_proj\", \"q_proj\", \"v_proj\"],\n",
    "    'lora_dropout': 0.1,\n",
    "    'bias': \"none\"\n",
    "} if lora else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the upstream model you want to use and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/hubert-base-ls960\"\n",
    "# model_name = \"facebook/wav2vec2-xls-r-300m\"\n",
    "\n",
    "upstream_model, feature_extractor = load_model(model_name, device=device, quantize=quantize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which experiments you want to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_monolingual = False\n",
    "\n",
    "run_multilingual_asr = False\n",
    "run_multilingual_lid = False\n",
    "run_multilingual_joint = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monolingual experiments (ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monolingual experiments\n",
    "models_by_language = {}\n",
    "monolingual_results = {}\n",
    "\n",
    "if run_monolingual:\n",
    "    # ASR task\n",
    "    for lang, data_pair in tqdm(TRAIN_PAIRS.items(), desc=\"Monolingual Experiments\"):\n",
    "        print(f\"\\nRunning Monolingual ASR for {lang} ({data_pair})\")\n",
    "\n",
    "        model, results, char_mappings = train_and_evaluate_monolingual(\n",
    "            lang=lang,\n",
    "            data_pair=data_pair,\n",
    "            upstream_model=upstream_model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            datasets=datasets,\n",
    "            device=device,\n",
    "            lora_config=lora_config,\n",
    "            quantize=quantize\n",
    "        )\n",
    "\n",
    "        test_model(\n",
    "            model=model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            datasets=datasets,\n",
    "            char_mappings=char_mappings,\n",
    "            model_type=\"monolingual\",\n",
    "            data_pair=data_pair,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        monolingual_results[lang] = results\n",
    "        models_by_language[lang] = model\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(base_dir, f\"{model_name.split('/')[-1]}_monolingual_asr_{lang}.pt\"))\n",
    "\n",
    "        clean_memory()\n",
    "\n",
    "    analyze_layer_weights(\n",
    "        models_by_language,\n",
    "        title=f\"{model_name.split('/')[-1].capitalize()} Monolingual Layer Weights\",\n",
    "        save_path=os.path.join(base_dir, f\"{model_name.split('/')[-1]}_monolingual_layer_weights.png\")\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(base_dir, f\"{model_name.split('/')[-1]}_monolingual_results.json\"), 'w') as f:\n",
    "        json.dump(monolingual_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual experiments (ASR, LID, ASR + LID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual experiments\n",
    "multilingual_results = {}\n",
    "multilingual_models = {}\n",
    "\n",
    "if run_multilingual_asr:\n",
    "    # ASR task\n",
    "    print(\"\\nRunning Multilingual ASR\")\n",
    "    asr_model, asr_results, asr_char_mappings = train_and_evaluate_multilingual(\n",
    "        upstream_model=upstream_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        task=\"asr\",\n",
    "        device=device,\n",
    "        lora_config=lora_config,\n",
    "        quantize=quantize\n",
    "        )\n",
    "\n",
    "    test_model(\n",
    "        model=asr_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        char_mappings=asr_char_mappings,\n",
    "        model_type=\"multilingual\",\n",
    "        task=\"asr\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    multilingual_results[\"asr\"] = asr_results\n",
    "    multilingual_models[\"asr\"] = asr_model\n",
    "\n",
    "    torch.save(asr_model.state_dict(), os.path.join(base_dir, f\"{model_name.split('/')[-1]}_multilingual_asr.pt\"))\n",
    "\n",
    "    clean_memory()\n",
    "\n",
    "if run_multilingual_lid:\n",
    "    # LID task\n",
    "    print(\"\\nRunning LID\")\n",
    "    lid_model, lid_results, lid_char_mappings = train_and_evaluate_multilingual(\n",
    "        upstream_model=upstream_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        task=\"lid\",\n",
    "        device=device,\n",
    "        lora_config=lora_config,\n",
    "        quantize=quantize\n",
    "    )\n",
    "\n",
    "    test_model(\n",
    "        model=lid_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        char_mappings=lid_char_mappings,\n",
    "        model_type=\"multilingual\",\n",
    "        task=\"lid\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    multilingual_results[\"lid\"] = lid_results\n",
    "    multilingual_models[\"lid\"] = lid_model\n",
    "\n",
    "    torch.save(lid_model.state_dict(), os.path.join(base_dir, f\"{model_name.split('/')[-1]}_multilingual_lid.pt\"))\n",
    "\n",
    "    clean_memory()\n",
    "\n",
    "if run_multilingual_joint:\n",
    "    # ASR+LID task\n",
    "    print(\"\\nRunning joint ASR+LID\")\n",
    "    joint_model, joint_results, joint_char_mappings = train_and_evaluate_multilingual(\n",
    "        upstream_model=upstream_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        task=\"asr+lid\",\n",
    "        device=device,\n",
    "        lora_config=lora_config,\n",
    "        quantize=quantize\n",
    "    )\n",
    "\n",
    "    test_model(\n",
    "        model=joint_model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        datasets=datasets,\n",
    "        char_mappings=joint_char_mappings,\n",
    "        model_type=\"multilingual\",\n",
    "        task=\"asr+lid\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    multilingual_results[\"asr+lid\"] = joint_results\n",
    "    multilingual_models[\"asr+lid\"] = joint_model\n",
    "\n",
    "    torch.save(joint_model.state_dict(), os.path.join(base_dir, f\"{model_name.split('/')[-1]}_multilingual_asr+lid.pt\"))\n",
    "\n",
    "    clean_memory()\n",
    "\n",
    "if run_multilingual_asr or run_multilingual_lid or run_multilingual_joint:\n",
    "    analyze_layer_weights(\n",
    "        multilingual_models,\n",
    "        title=f\"{model_name.split('/')[-1].capitalize()} Multilingual Layer Weights\",\n",
    "        save_path=os.path.join(base_dir, f\"{model_name.split('/')[-1]}_multilingual_layer_weights.png\")\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(base_dir, f\"{model_name.split('/')[-1]}_multilingual_results.json\"), 'w') as f:\n",
    "        json.dump(multilingual_results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
